E:\Anaconda3_4.2.0_64bit\python.exe D:/code/deep_learning_test/cnn/simple_cnn_use_mnist_data.py
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
2018-03-25 16:32:15.655044: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:15.655495: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:15.655930: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:15.656371: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:15.656805: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:15.657222: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:15.657631: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:15.658036: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-03-25 16:32:16.533618: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:887] Found device 0 with properties:
name: GeForce GTX 950M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:01:00.0
Total memory: 4.00GiB
Free memory: 3.35GiB
2018-03-25 16:32:16.534112: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:908] DMA: 0
2018-03-25 16:32:16.534395: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:918] 0:   Y
2018-03-25 16:32:16.535021: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0)
Tensor("MaxPool:0", shape=(?, 14, 14, 32), dtype=float32) <tf.Variable 'Variable_2:0' shape=(5, 5, 32, 64) dtype=float32_ref>
 step 0 , training accuracy 0.14
 step 100 , training accuracy 0.86
 step 200 , training accuracy 0.94
 step 300 , training accuracy 0.84
 step 400 , training accuracy 0.96
 step 500 , training accuracy 0.94
 step 600 , training accuracy 0.98
 step 700 , training accuracy 0.92
 step 800 , training accuracy 0.98
 step 900 , training accuracy 0.94
 step 1000 , training accuracy 0.96
 step 1100 , training accuracy 0.96
 step 1200 , training accuracy 0.98
 step 1300 , training accuracy 1
 step 1400 , training accuracy 1
 step 1500 , training accuracy 1
 step 1600 , training accuracy 0.98
 step 1700 , training accuracy 0.96
 step 1800 , training accuracy 0.98
 step 1900 , training accuracy 0.96
 step 2000 , training accuracy 1
 step 2100 , training accuracy 0.98
 step 2200 , training accuracy 0.98
 step 2300 , training accuracy 1
 step 2400 , training accuracy 0.98
 step 2500 , training accuracy 0.98
 step 2600 , training accuracy 0.96
 step 2700 , training accuracy 1
 step 2800 , training accuracy 1
 step 2900 , training accuracy 0.98
 step 3000 , training accuracy 1
 step 3100 , training accuracy 0.96
 step 3200 , training accuracy 0.94
 step 3300 , training accuracy 0.98
 step 3400 , training accuracy 0.96
 step 3500 , training accuracy 0.96
 step 3600 , training accuracy 1
 step 3700 , training accuracy 1
 step 3800 , training accuracy 0.96
 step 3900 , training accuracy 1
 step 4000 , training accuracy 1
 step 4100 , training accuracy 1
 step 4200 , training accuracy 0.98
 step 4300 , training accuracy 0.98
 step 4400 , training accuracy 1
 step 4500 , training accuracy 1
 step 4600 , training accuracy 1
 step 4700 , training accuracy 0.98
 step 4800 , training accuracy 1
 step 4900 , training accuracy 1
 step 5000 , training accuracy 1
 step 5100 , training accuracy 1
 step 5200 , training accuracy 0.98
 step 5300 , training accuracy 0.96
 step 5400 , training accuracy 0.98
 step 5500 , training accuracy 1
 step 5600 , training accuracy 1
 step 5700 , training accuracy 1
 step 5800 , training accuracy 0.98
 step 5900 , training accuracy 1
 step 6000 , training accuracy 0.98
 step 6100 , training accuracy 1
 step 6200 , training accuracy 1
 step 6300 , training accuracy 0.98
 step 6400 , training accuracy 0.98
 step 6500 , training accuracy 1
 step 6600 , training accuracy 0.98
 step 6700 , training accuracy 0.98
 step 6800 , training accuracy 1
 step 6900 , training accuracy 1
 step 7000 , training accuracy 1
 step 7100 , training accuracy 1
 step 7200 , training accuracy 1
 step 7300 , training accuracy 1
 step 7400 , training accuracy 1
 step 7500 , training accuracy 0.98
 step 7600 , training accuracy 1
 step 7700 , training accuracy 1
 step 7800 , training accuracy 1
 step 7900 , training accuracy 1
 step 8000 , training accuracy 1
 step 8100 , training accuracy 1
 step 8200 , training accuracy 0.98
 step 8300 , training accuracy 1
 step 8400 , training accuracy 0.98
 step 8500 , training accuracy 1
 step 8600 , training accuracy 1
 step 8700 , training accuracy 0.96
 step 8800 , training accuracy 1
 step 8900 , training accuracy 1
 step 9000 , training accuracy 0.98
 step 9100 , training accuracy 1
 step 9200 , training accuracy 1
 step 9300 , training accuracy 1
 step 9400 , training accuracy 0.98
 step 9500 , training accuracy 1
 step 9600 , training accuracy 1
 step 9700 , training accuracy 0.98
 step 9800 , training accuracy 1
 step 9900 , training accuracy 1
 step 10000 , training accuracy 1
 step 10100 , training accuracy 0.98
 step 10200 , training accuracy 1
 step 10300 , training accuracy 1
 step 10400 , training accuracy 1
 step 10500 , training accuracy 1
 step 10600 , training accuracy 1
 step 10700 , training accuracy 0.98
 step 10800 , training accuracy 0.98
 step 10900 , training accuracy 0.98
 step 11000 , training accuracy 1
 step 11100 , training accuracy 1
 step 11200 , training accuracy 0.98
 step 11300 , training accuracy 1
 step 11400 , training accuracy 1
 step 11500 , training accuracy 1
 step 11600 , training accuracy 0.98
 step 11700 , training accuracy 1
 step 11800 , training accuracy 1
 step 11900 , training accuracy 1
 step 12000 , training accuracy 1
 step 12100 , training accuracy 1
 step 12200 , training accuracy 0.98
 step 12300 , training accuracy 1
 step 12400 , training accuracy 1
 step 12500 , training accuracy 1
 step 12600 , training accuracy 1
 step 12700 , training accuracy 1
 step 12800 , training accuracy 0.98
 step 12900 , training accuracy 1
 step 13000 , training accuracy 1
 step 13100 , training accuracy 0.96
 step 13200 , training accuracy 1
 step 13300 , training accuracy 1
 step 13400 , training accuracy 1
 step 13500 , training accuracy 1
 step 13600 , training accuracy 1
 step 13700 , training accuracy 1
 step 13800 , training accuracy 1
 step 13900 , training accuracy 1
 step 14000 , training accuracy 1
 step 14100 , training accuracy 1
 step 14200 , training accuracy 1
 step 14300 , training accuracy 1
 step 14400 , training accuracy 1
 step 14500 , training accuracy 1
 step 14600 , training accuracy 1
 step 14700 , training accuracy 1
 step 14800 , training accuracy 1
 step 14900 , training accuracy 1
 step 15000 , training accuracy 1
 step 15100 , training accuracy 1
 step 15200 , training accuracy 0.98
 step 15300 , training accuracy 1
 step 15400 , training accuracy 1
 step 15500 , training accuracy 1
 step 15600 , training accuracy 1
 step 15700 , training accuracy 1
 step 15800 , training accuracy 1
 step 15900 , training accuracy 1
 step 16000 , training accuracy 1
 step 16100 , training accuracy 1
 step 16200 , training accuracy 1
 step 16300 , training accuracy 1
 step 16400 , training accuracy 1
 step 16500 , training accuracy 1
 step 16600 , training accuracy 1
 step 16700 , training accuracy 1
 step 16800 , training accuracy 1
 step 16900 , training accuracy 1
 step 17000 , training accuracy 1
 step 17100 , training accuracy 1
 step 17200 , training accuracy 1
 step 17300 , training accuracy 1
 step 17400 , training accuracy 1
 step 17500 , training accuracy 1
 step 17600 , training accuracy 1
 step 17700 , training accuracy 1
 step 17800 , training accuracy 1
 step 17900 , training accuracy 1
 step 18000 , training accuracy 1
 step 18100 , training accuracy 1
 step 18200 , training accuracy 1
 step 18300 , training accuracy 1
 step 18400 , training accuracy 0.98
 step 18500 , training accuracy 1
 step 18600 , training accuracy 1
 step 18700 , training accuracy 1
 step 18800 , training accuracy 1
 step 18900 , training accuracy 1
 step 19000 , training accuracy 1
 step 19100 , training accuracy 1
 step 19200 , training accuracy 1
 step 19300 , training accuracy 1
 step 19400 , training accuracy 1
 step 19500 , training accuracy 1
 step 19600 , training accuracy 1
 step 19700 , training accuracy 1
 step 19800 , training accuracy 1
 step 19900 , training accuracy 1
2018-03-25 16:39:26.139069: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.59GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-03-25 16:39:26.139655: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-03-25 16:39:27.054819: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.90GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
test accuracy 0.9925

Process finished with exit code 0
